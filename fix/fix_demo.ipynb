{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f590ce-d401-4301-82e4-7e69c52a3488",
   "metadata": {},
   "source": [
    "# Welcome to FIX!\n",
    "In this notebook, we give some examples of **loading dataset** and **running benchmarks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c6d98-06d2-4c35-a5da-a48245fa51ae",
   "metadata": {},
   "source": [
    "# Part 1: Loading Datasets\n",
    "\n",
    "We'll first talk about how to load the datasets described in our paper.\n",
    "FIX is built using the `exlib` library, which we load using a local version for now. You can uncomment the `!pip install exlib` line and comment out the `import sys; sys.path.insert(0, \"../src\")` line if you do not have a local version you are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948b58aa-8a5d-4f50-8d65-c4fda84adc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonxue/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install exlib\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mexlib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/exlib/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m features\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explainers\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/exlib/datasets/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eraser_movies\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m informer_models\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mass_maps\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilingual_politeness\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supernova\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/exlib/datasets/mass_maps.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mexlib\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Baselines\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmass_maps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MassMapsOracle, MassMapsOne\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseFixScore\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/exlib/features/vision/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwatershed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WatershedGroups\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SamGroups\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CraftGroups\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchipelago\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArchipelagoGroups\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/exlib_test/lib/python3.11/site-packages/exlib/features/vision/craft.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "# !pip install exlib\n",
    "import exlib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import datasets as huggingface_datasets # Not to be confused with exlib.datasets!\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e7169-7bdd-4b4e-8ef9-842f26d649dd",
   "metadata": {},
   "source": [
    "## Cholecystectomy Dataset\n",
    "\n",
    "This dataset contains image data from cholecystectomy surgery (gallbladder removal). The fields are as follows:\n",
    "\n",
    "* `image`: A view of the surgery.\n",
    "* `gonogo`: Whether it is safe or unsafe to operate. Background (0), safe (1), and unsafe (2).\n",
    "* `organs`: Relevant organ structures for surgery. Background (0), liver (1), gallbladder (2), and hepatocystic triangle (3). These are the expert-specified interpretable features.\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/cholecystectomy).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/cholec.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc4493-33f3-4341-97ba-1e0ca969dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholec_dataset = exlib.datasets.cholec.CholecDataset(split=\"test\")\n",
    "cholec_item = cholec_dataset[0]\n",
    "cholec_image = cholec_item[\"image\"]\n",
    "cholec_gonogo = cholec_item[\"gonogo\"]\n",
    "cholec_organs = cholec_item[\"organs\"]\n",
    "\n",
    "print(\"image:\", cholec_image.shape, cholec_image.dtype)\n",
    "print(\"gonogo:\", cholec_gonogo.shape, cholec_gonogo.dtype)\n",
    "print(\"organs:\", cholec_organs.shape, cholec_organs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999a04b-6ca7-4e22-ba4c-2656e74da0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "for i in range(3): ax[i].set_axis_off()\n",
    "\n",
    "cholec_image = torchvision.transforms.GaussianBlur(41, (50.0, 50.0))(cholec_image)\n",
    "\n",
    "ax[0].imshow(cholec_image.numpy().transpose(1,2,0))\n",
    "ax[1].imshow(cholec_gonogo.numpy())\n",
    "ax[2].imshow(cholec_organs.numpy())\n",
    "\n",
    "ax[0].set_title(\"Original Image (blurred)\")\n",
    "ax[1].set_title(\"Back (0), Safe (1), Unsafe (2)\")\n",
    "ax[2].set_title(\"Back (0), Liver (1), Gallb. (2), Hept. (3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88265756-bbce-4341-beca-f8c8c506ce06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91651f84-81a3-4355-a237-bbb647a785fd",
   "metadata": {},
   "source": [
    "## Chest X-ray Dataset\n",
    "\n",
    "This dataset contains vision data for chest X-ray pathology identification.\n",
    "The fields are as follows:\n",
    "\n",
    "* `image`: The image of the chest X-ray.\n",
    "* `pathols`: A binary vector that denotes which of the 14 pathologies are present.\n",
    "* `struct`: A collection of binary masks over the image for the relevant anatomical structures. These are the expert-specified interpretable features.\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/chestx).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/chestx.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cb399-36f5-469d-a977-cb74a5996613",
   "metadata": {},
   "outputs": [],
   "source": [
    "chestx_dataset = exlib.datasets.chestx.ChestXDataset(split=\"test\")\n",
    "\n",
    "# Find an image that has at least 2 pathologies present\n",
    "for i in range(10000):\n",
    "    chestx_item = chestx_dataset[i]\n",
    "    if chestx_item[\"pathols\"].sum() > 1: break\n",
    "\n",
    "chestx_image = chestx_item[\"image\"]\n",
    "chestx_pathols = chestx_item[\"pathols\"]\n",
    "chestx_structs = chestx_item[\"structs\"]\n",
    "\n",
    "print(\"image:\", chestx_image.shape, chestx_image.dtype)\n",
    "print(\"pathols:\", chestx_pathols.shape, chestx_pathols.dtype)\n",
    "print(\"structs:\", chestx_structs.shape, chestx_structs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9788f7-5a54-4227-8451-8cf80b4cc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All pathologies:\")\n",
    "print(\", \".join([f\"({i}) {s}\" for i,s in enumerate(chestx_dataset.pathology_names)]))\n",
    "\n",
    "print(\"\\nAll structures:\")\n",
    "print(\", \".join([f\"({i}) {s}\" for i,s in enumerate(chestx_dataset.structure_names)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa3c6a-a18c-4992-8738-610a5e9aba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplot_mosaic([\n",
    "    ([\"image\"] + [f\"struct{i}\" for i in range(7)]),\n",
    "    ([\".\"] + [f\"struct{i}\" for i in range(7,14)]),\n",
    "], figsize=(14,4))\n",
    "\n",
    "for _, a in ax.items(): a.set_axis_off()\n",
    "\n",
    "struct_titles = chestx_dataset.structure_names\n",
    "ax[\"image\"].imshow(chestx_image.numpy().transpose(1,2,0), cmap=\"gray\")\n",
    "ax[\"image\"].set_title(\"Image\")\n",
    "\n",
    "for i in range(14):\n",
    "    mask_t = chestx_structs[i].unsqueeze(0)\n",
    "    ax[f\"struct{i}\"].imshow((mask_t.numpy().transpose(1,2,0)) * 2, cmap=\"gray\")\n",
    "    ax[f\"struct{i}\"].set_title(f\"{struct_titles[i][:10]} (T)\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7167a5-9d6a-4dc7-8296-9684aa795062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pathologies present:\")\n",
    "for idx in chestx_pathols.nonzero():\n",
    "    print(\"*\", chestx_dataset.pathology_names[idx.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30415128-a40e-46b3-aaa9-bd20a4b5b5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e98c23-4d5c-4a93-90f1-289d5e9b7627",
   "metadata": {},
   "source": [
    "## Cosmological Mass Maps Dataset\n",
    "\n",
    "This dataset contains clean simulated weak lensing maps without noise.\n",
    "The relevant fields are as follows:\n",
    "* `input`: A (1,66,66)-shaped weak lensing map\n",
    "* `label`: A pair of numbers that represents the cosmological parameters Omega_m and sigma_8. In this dataset, the expert-specified features are absent.\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/massmaps-cosmogrid-100k).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/mass_maps.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a88032-65c4-48c3-9937-890c94529807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# massmaps_dataset = huggingface_datasets.load_dataset(exlib.datasets.mass_maps.DATASET_REPO, split=\"test\")\n",
    "massmaps_dataset = exlib.datasets.mass_maps.MassMapsDataset(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3223891-93d2-427f-8de8-b9f344349ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few examples of mass maps\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,4))\n",
    "for i in range(len(ax)):\n",
    "    mm_input = massmaps_dataset[i][\"input\"]\n",
    "    mm_label = massmaps_dataset[i][\"label\"]\n",
    "    ax[i].imshow(mm_input.numpy().transpose(1,2,0))\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].set_title(f\"Omega_m = {mm_label[0]:.3f},  sigma_8 = {mm_label[1]:.3f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b677a9-e45c-48d0-bc43-9235e87aba54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "182156c3-fd06-4401-a90b-6efbb3e94550",
   "metadata": {},
   "source": [
    "## Emotion Dataset\n",
    "\n",
    "This dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral. The fields are as follows:\n",
    "* `text`: The reddit comment.\n",
    "* `labels`: The emotion annotations.\n",
    "* `comment_id`: Unique identifier of the comment.\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/emotion).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/emotion.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ad1b8-94a9-443e-bf50-95b11fa2d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataset = exlib.datasets.emotion.EmotionDataset(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c17b58-fe44-4c85-b656-c1a57a853b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataloader = torch.utils.data.DataLoader(emotion_dataset, batch_size=4, shuffle=False)\n",
    "emotion_model = exlib.datasets.emotion.EmotionClassifier().eval()\n",
    "\n",
    "for batch in emotion_dataloader: \n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    output = emotion_model(input_ids, attention_mask)\n",
    "    utterances = [\n",
    "        emotion_dataset.tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "        for input_id in input_ids\n",
    "    ]\n",
    "    for utterance, label in zip(utterances, output.logits):\n",
    "        id_str = emotion_model.model.config.id2label[label.argmax().item()]\n",
    "        print(\"Text: {}\\nEmotion: {}\\n\".format(utterance, id_str))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f059d0-2bd5-4378-9c8d-4909b9b9d540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "222a1efe-132c-40f9-8aab-5ad006a952c7",
   "metadata": {},
   "source": [
    "## Multilingual Politeness Dataset\n",
    "\n",
    "This dataset contains conversation snippets from Wikipedia's editor talk pages. The fields are as follows:\n",
    "* `text`: The Wikipedia's editor talk page conversation snippets.\n",
    "* `politeness`: politeness level from -2 (very rude) to 2 (very polite).\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/multilingual_politeness).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/multilingual_politeness.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7174141-0a53-4b79-a8ed-ba8b23aa2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_dataset = exlib.datasets.multilingual_politeness.PolitenessDataset(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa010e5-dac1-4f08-81a8-d4e6a454b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_dataloader = torch.utils.data.DataLoader(politeness_dataset, batch_size=4, shuffle=False)\n",
    "politeness_model = exlib.datasets.multilingual_politeness.PolitenessClassifier().eval()\n",
    "\n",
    "for batch in politeness_dataloader: \n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    output = politeness_model(input_ids, attention_mask)\n",
    "    utterances = [\n",
    "        politeness_dataset.tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "        for input_id in input_ids\n",
    "    ]\n",
    "    for utterance, label in zip(utterances, output):\n",
    "        print(\"Text: {}\\nPoliteness: {}\\n\".format(utterance, label.item()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275bbe2-06c5-41da-a28b-2c00951318be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b784578e-b2e2-4df0-a119-f1678df02a9e",
   "metadata": {},
   "source": [
    "## Supernova Dataset\n",
    "\n",
    "This dataset contains astronomical time-series that has 18 types of astronomical sources. The fields are as follows:\n",
    "* `label`: The class of the object.\n",
    "* `times_wv`: 2D array of shape containing observation times (modified Julian days, MJD) and filter (wavelength) for each observation.\n",
    "* `target`: 2D array of shape containing the flux (arbitrary units) and flux error for each observation.\n",
    "\n",
    "You can access the dataset [here on Hugging Face](https://huggingface.co/datasets/BrachioLab/supernova-timeseries).\n",
    "For more information, see this [notebook example](https://colab.research.google.com/github/BrachioLab/exlib/blob/main/notebooks/fix/supernova.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3c12b-e114-4c9b-8ce0-418e73e20240",
   "metadata": {},
   "outputs": [],
   "source": [
    "supernova_dataset = exlib.datasets.supernova.SupernovaDataset(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a8fe9-6159-4a2a-8b0f-03849cf14628",
   "metadata": {},
   "outputs": [],
   "source": [
    "supernova_item = supernova_dataset.dataset[0]\n",
    "times_wv = torch.tensor(supernova_item[\"times_wv\"])\n",
    "xs = times_wv[:, 0]\n",
    "ys = torch.tensor(supernova_item[\"target\"])[:, 0]\n",
    "times_wv, xs, ys = times_wv[ys!=0], xs[ys!=0], ys[ys!=0]\n",
    "unique_wls = [3670.69, 4826.85, 6223.24, 7545.98, 8590.9, 9710.28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1b483-7ef6-4381-ad43-baf104133c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "for wl in unique_wls:\n",
    "    mask = times_wv[:, 1] == wl\n",
    "    plt.scatter(xs[mask], ys[mask], label=f'{wl:.2f}', cmap='viridis')\n",
    "\n",
    "plt.title(f'Class: {supernova_item[\"label\"]}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(title='Wavelength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fdc5c-68a2-4f61-ad88-e9f4e1f2c514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c89c3a8-c8c6-45a2-aef3-8ae66eea3670",
   "metadata": {},
   "source": [
    "# Part 2: Running benchmarks and evaluations\n",
    "\n",
    "We now show how to run some benchmarks + evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f60bfb-ec8e-4099-8884-5e2423213b81",
   "metadata": {},
   "source": [
    "## Vision Example (Cholecystectomy)\n",
    "\n",
    "We show an example of groups generated by the quickshift segmentation algorithm compared to those that are labeled by our surgeon experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a4433-69e0-4c47-9662-1df3ccaa5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholec_dataset = exlib.datasets.cholec.CholecDataset(split=\"test\")\n",
    "cholec_item = cholec_dataset[0]\n",
    "cholec_image = cholec_item[\"image\"]\n",
    "cholec_organs = cholec_item[\"organs\"]\n",
    "\n",
    "quickshift_feature_extractor = exlib.features.vision.QuickshiftGroups(max_groups=8)\n",
    "quickshift_groups = quickshift_feature_extractor(cholec_image.unsqueeze(0))[0]\n",
    "\n",
    "# Image, expert-specified groups, and quickshift-generated groups\n",
    "cholec_image.shape, cholec_organs.shape, quickshift_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998246c-f315-4725-997e-9b5af23c30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize these things\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "for a in ax: a.set_axis_off()\n",
    "\n",
    "cholec_image = torchvision.transforms.GaussianBlur(41, (50.0, 50.0))(cholec_image)\n",
    "\n",
    "ax[0].imshow(cholec_image.numpy().transpose(1,2,0))\n",
    "ax[1].imshow(cholec_item[\"organs\"].numpy())\n",
    "ax[2].imshow((torch.arange(8).view(-1,1,1) * quickshift_groups).sum(dim=0).numpy())\n",
    "\n",
    "ax[0].set_title(\"Original image (blurred)\")\n",
    "ax[1].set_title(\"Expert-specified groups\")\n",
    "ax[2].set_title(\"Quickshift-generated groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86d3ce-c922-4672-959a-ece1829be0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects a pair of (N,C,H,W)-shaped things\n",
    "cholec_metric = exlib.datasets.cholec.CholecFixScore()\n",
    "\n",
    "# Adjust things to be able to be put into cholec_metric\n",
    "cholec_organs_mask = F.one_hot(cholec_organs).permute(2,0,1).unsqueeze(0) # (1,num_true_groups,H,W)\n",
    "batched_qs_groups = quickshift_groups.unsqueeze(0) # (1,num_pred_groups,H,W)\n",
    "\n",
    "# The FIX score is computed for each pixel, and we just take the average\n",
    "cholec_fix_score = cholec_metric(groups_pred=batched_qs_groups, groups_true=cholec_organs_mask)\n",
    "print(cholec_fix_score.shape, cholec_fix_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6966d8f-e4db-492b-842a-ba1142bf9185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66fa31b5-9836-47e9-9cd3-dfda29ddb624",
   "metadata": {},
   "source": [
    "## Natural Language Example (Multilingual Politeness)\n",
    "\n",
    "We show an example of the groups demarcated at the sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6e4e6-4417-4e91-94b4-c935b8748a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_dataset = exlib.datasets.multilingual_politeness.PolitenessDataset(split=\"test\")\n",
    "politeness_item = politeness_dataset[0]\n",
    "politeness_word_list = [w for w in politeness_item[\"word_list\"] if w.strip()]\n",
    "\n",
    "sentence_feature_extractor = exlib.features.text.SentenceGroups(distinct=26, scaling=1.5)\n",
    "sentence_groups = sentence_feature_extractor(politeness_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdbd5c-19f6-4576-96d6-bb3f0d7c99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(politeness_word_list), \"\\n\")\n",
    "for i, g in enumerate(sentence_groups):\n",
    "    sentence = \" \".join([politeness_word_list[ni.item()] for ni in g.nonzero()])\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f84b74-4e5a-4589-aacd-3e948ca0fc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2da8599e-fdf0-40ad-ac9d-cb4c7a5a4581",
   "metadata": {},
   "source": [
    "## Time-series Example (Supernova)\n",
    "\n",
    "We show an example of groups based on slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd381a6e-5bd4-4380-abd6-ab5e13a66d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "supernova_dataset = exlib.datasets.supernova.SupernovaDataset(split=\"test\")\n",
    "supernova_item = supernova_dataset.dataset[0]\n",
    "times_wv = torch.tensor(supernova_item[\"times_wv\"])\n",
    "xs = times_wv[:, 0]\n",
    "ys = torch.tensor(supernova_item[\"target\"])[:, 0]\n",
    "times_wv, xs, ys = times_wv[ys!=0], xs[ys!=0], ys[ys!=0]\n",
    "unique_wls = [3670.69, 4826.85, 6223.24, 7545.98, 8590.9, 9710.28]\n",
    "\n",
    "slice_feature_extractor = exlib.features.time_series.SliceGroups(ngroups=10, window_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c6a09-1e18-4baa-8b78-810914793e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "supernova_dataloader = exlib.datasets.supernova_helper.create_test_dataloader_raw(\n",
    "    dataset = supernova_dataset,\n",
    "    batch_size = 5\n",
    ")\n",
    "\n",
    "for batch in supernova_dataloader:\n",
    "    slice_groups = slice_feature_extractor(**batch)\n",
    "    slice_groups = slice_groups[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd4c5b-fbea-48dc-98ea-f2719da4245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# First plot the wavelengths like before\n",
    "for wl in unique_wls:\n",
    "    mask = times_wv[:, 1] == wl\n",
    "    plt.scatter(xs[mask], ys[mask], label=f'{wl:.2f}', cmap=\"viridis\")\n",
    "\n",
    "# Then overlay the groups\n",
    "cmap = plt.cm.get_cmap(\"viridis\")\n",
    "for i, g in enumerate(slice_groups):\n",
    "    if g.sum() == 0: continue\n",
    "    xmin = xs[g.nonzero().min().item()].item()\n",
    "    xmax = xs[g.nonzero().max().item()].item()\n",
    "    plt.axvspan(xmin, xmax, alpha=0.3, facecolor=cmap(i/len(slice_groups)))\n",
    "\n",
    "plt.title(f'Class: {supernova_item[\"label\"]}')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(title='Wavelength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fd674-3bb6-48b1-bc49-239b22ad12a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d95351a-d087-4d6e-9ef5-edf283ee1bfc",
   "metadata": {},
   "source": [
    "# Part 3: Get scores for a list of baselines\n",
    "\n",
    "We now show how to get FixScore for a list of feature extractors for their corresponding datasets.\n",
    "This part can be run standalone from the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f19b2-5a31-458e-9dd8-e239be0756ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install exlib\n",
    "import sys; sys.path.insert(0, \"../src\")\n",
    "import exlib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import datasets as huggingface_datasets # Not to be confused with exlib.datasets!\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052bc19-6ff3-43a3-96b8-5c74da9be176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import exlib.datasets as xd\n",
    "import exlib.features.vision as xfv\n",
    "import exlib.features.time_series as xfts\n",
    "import exlib.features.text as xft\n",
    "from datasets import load_dataset\n",
    "\n",
    "# there is a preprocess_xx in each folder\n",
    "\n",
    "l = [\n",
    "    # dataset, feature_extractor, metric, preprocess (can be \n",
    "    (xd.cholec.CholecDataset(split=\"test\"), xfv.QuickshiftGroups(max_groups=8), xd.cholec.CholecFixScore(), xd.cholec.preprocess_cholec),\n",
    "    (xd.chestx.ChestXDataset(split=\"test\"), xfv.QuickshiftGroups(max_groups=20), xd.chestx.ChestXFixScore(), xd.chestx.preprocess_chestx),\n",
    "    (xd.mass_maps.MassMapsDataset(split=\"test\"), xfv.QuickshiftGroups(kernel_size=5, \n",
    "    max_dist=10, sigma=0.2, max_groups=25), xd.mass_maps.MassMapsFixScore(), xd.mass_maps.preprocess_mass_maps),\n",
    "    (xd.supernova.SupernovaDataset(split=\"test\"), xfts.SliceGroups(ngroups=5, window_size=100), xd.supernova.SupernovaFixScore(),\n",
    "    xd.supernova.preprocess_supernova),\n",
    "    (xd.multilingual_politeness.PolitenessDataset(split=\"test\"), \n",
    "     xft.WordGroups(distinct=26, scaling=1.5), xd.multilingual_politeness.PolitenessFixScore(),\n",
    "    xd.multilingual_politeness.preprocess_politeness),\n",
    "    (xd.emotion.EmotionDataset(split=\"test\"), \n",
    "     xft.WordGroups(distinct=4, scaling=1.5), xd.emotion.EmotionFixScore(),\n",
    "    xd.emotion.preprocess_emotion)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c26022-ac2e-4516-89bc-f75ae91fa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for dataset, feature_extractor, metric, preprocess in l:\n",
    "    torch.manual_seed(1234)\n",
    "    if hasattr(dataset, 'get_dataloader'): # if the dataset has its own dataloader, then use that\n",
    "        dataloader = dataset.get_dataloader(batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    feature_extractor = feature_extractor.to(device)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    scores = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        # Preprocess the batch using the preprocess function for that dataset\n",
    "        X, metric_inputs = preprocess(batch)\n",
    "        # move inputs to device if they are tensors\n",
    "        X = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in X.items()}\n",
    "        metric_inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in metric_inputs.items()}\n",
    "        \n",
    "        # extract expert features\n",
    "        expert_feats = feature_extractor(**X)\n",
    "        # evaluate metric scores\n",
    "        score = metric(expert_feats, **metric_inputs)\n",
    "        \n",
    "        if not isinstance(score, torch.Tensor):\n",
    "            score = torch.tensor(score)\n",
    "        scores.append(score)\n",
    "        if len(scores) > 5: # comment out if evaluating on all the data\n",
    "            break\n",
    "    all_scores.append(torch.stack(scores).view(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9a4ad-d5bb-4ec7-a4f9-a1c426989b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c125f-600d-4d10-be28-22ac69e23049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of each baseline\n",
    "\n",
    "import numpy as np\n",
    "from exlib.utils import bootstrap\n",
    "\n",
    "for i in range(len(all_scores)):\n",
    "    print(i, np.mean(all_scores[i]), bootstrap(torch.tensor(all_scores[i])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8da19e-8695-4d6c-9722-7b5f3b259075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
