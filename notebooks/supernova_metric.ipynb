{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a3eec2-5c1f-4691-942f-7204e3ffa7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow_hotfix\n",
    "from informer_models import InformerConfig, InformerForSequenceClassification\n",
    "import torch\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from connect_later.pretrain import setup_model_config\n",
    "from collections import namedtuple\n",
    "\n",
    "from connect_later.dataset_preprocess_raw import create_train_dataloader_raw, create_test_dataloader_raw\n",
    "from connect_later.informer_models import InformerForSequenceClassification\n",
    "from connect_later.pretrain import get_dataset, setup_model_config\n",
    "\n",
    "pa.PyExtensionType.set_auto_load(True)\n",
    "pyarrow_hotfix.uninstall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309ecc0d-daef-48cc-bcd8-ee1e52e01937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"BrachioLab/supernova-timeseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4bf1a6-cce1-4f56-b797-5d65395f9807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c78563eb-6aab-4856-92e2-0408e5ebeddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['object_id', 'times_wv', 'lightcurve', 'label', 'redshift', 'hostgal_specz', 'hostgal_photoz', 'hostgal_photoz_err', 'ddf_bool'],\n",
       "        num_rows: 7066\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['object_id', 'times_wv', 'lightcurve', 'label', 'redshift', 'hostgal_specz', 'hostgal_photoz', 'hostgal_photoz_err', 'ddf_bool'],\n",
       "        num_rows: 782\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['object_id', 'times_wv', 'lightcurve', 'label', 'redshift', 'hostgal_specz', 'hostgal_photoz', 'hostgal_photoz_err', 'ddf_bool'],\n",
       "        num_rows: 3492890\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80657904-4414-4f9d-8afe-ea8b65f83fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_labels(dataset):\n",
    "    label_counts = Counter(dataset['label'])\n",
    "    return dict(label_counts)\n",
    "\n",
    "train_label_counts = count_labels(dataset['train'])\n",
    "validation_label_counts = count_labels(dataset['validation'])\n",
    "test_label_counts = count_labels(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1150f3c6-bb15-4d34-82cd-83abe9c382fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Counts: {92: 215, 88: 333, 42: 1074, 90: 2082, 65: 883, 16: 832, 67: 187, 95: 158, 62: 436, 15: 446, 52: 165, 6: 136, 64: 92, 53: 27}\n",
      "Validation Label Counts: {92: 24, 88: 37, 42: 119, 90: 231, 65: 98, 16: 92, 67: 21, 95: 17, 62: 48, 15: 49, 52: 18, 6: 15, 64: 10, 53: 3}\n",
      "Test Label Counts: {42: 1000150, 90: 1659831, 16: 96572, 67: 40193, 62: 175094, 993: 9680, 92: 197155, 52: 63664, 88: 101424, 65: 93494, 991: 533, 992: 1702, 15: 13555, 95: 35782, 6: 1303, 53: 1453, 994: 1172, 64: 133}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Label Counts:\", train_label_counts)\n",
    "print(\"Validation Label Counts:\", validation_label_counts)\n",
    "print(\"Test Label Counts:\", test_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3872cf28-ea9f-41d5-8048-f1a0fb09d565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#14 balanced classes\n",
    "#15 balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7e9588c-813a-45ce-885d-024f722fbed2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{64, 65, 67, 6, 15, 16, 88, 90, 92, 95, 42, 52, 53, 62}\n"
     ]
    }
   ],
   "source": [
    "unique_labels_train = set(dataset['train']['label'])\n",
    "unique_labels_validation = set(dataset['validation']['label'])\n",
    "unique_labels_test = set(dataset['test']['label'])\n",
    "\n",
    "# Combine all unique labels across splits\n",
    "all_unique_labels = unique_labels_train.union(unique_labels_validation)\n",
    "\n",
    "print(all_unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adaf8454-a6bb-4746-9983-b05da13bee30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{64, 65, 67, 6, 42, 15, 16, 52, 53, 88, 90, 92, 62, 95}\n",
      "{64, 65, 67, 6, 42, 15, 16, 52, 53, 88, 90, 92, 62, 95}\n",
      "{992, 993, 65, 67, 994, 64, 6, 42, 15, 16, 52, 53, 95, 88, 90, 92, 62, 991}\n"
     ]
    }
   ],
   "source": [
    "print(unique_labels_train)\n",
    "print(unique_labels_validation)\n",
    "print(unique_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1209cd44-341f-4efb-a65d-fadade9ee9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fdfc874b6545a6859a1ec9a0ef6ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eab14553b344f599c5af07ebffb363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/88.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 14\n",
      "Using Fourier PE\n",
      "classifier dropout: 0.2\n"
     ]
    }
   ],
   "source": [
    "model = InformerForSequenceClassification.from_pretrained(\"BrachioLab/supernova-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b03f90-1990-4278-a32b-c4e58c0166eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b24a95df784d3882c97f6ce987364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size: 792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff578c2cb367482e9c2d6f9e32d02552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove nans dataset size: 792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a172c9c0f23641a09a43b0d450cfc626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = InformerConfig.from_pretrained(\"BrachioLab/supernova-classification\")\n",
    "test_dataloader = create_test_dataloader_raw(\n",
    "    config=config,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=256,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2805cba7-a628-435a-8426-4d38e8c59c94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 0\n",
      "processing batch 1\n",
      "processing batch 2\n",
      "processing batch 3\n",
      "accuracy: 0.8017676767676768\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    print(f\"processing batch {i}\")\n",
    "    batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    y_true.extend(batch['labels'].cpu().numpy())\n",
    "    y_pred.extend(torch.argmax(outputs.logits, dim=2).squeeze().cpu().numpy())\n",
    "print(f\"accuracy: {sum([1 for i, j in zip(y_true, y_pred) if i == j]) / len(y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce57e30d-75e3-4485-9472-d093cc9b41a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "target_column = test_dataset['target']\n",
    "times_wv_column = test_dataset['times_wv']\n",
    "print(len(target_column[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51895fc-523c-4174-8cd4-3b0a74be72ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_humps(lst):\n",
    "    hump_count = 0\n",
    "    in_hump = False\n",
    "    for elem in lst:\n",
    "        if elem == 1 and not in_hump:\n",
    "            hump_count += 1\n",
    "            in_hump = True\n",
    "        elif elem == 0:\n",
    "            in_hump = False\n",
    "    return hump_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "534372a5-ddcd-4339-8b08-230d7d9c8493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ones_count = [sublist.count(1) for sublist in daf_list]\n",
    "humps_per_sublist = [count_humps(sublist) for sublist in daf_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c6b86fa-50ed-4782-9e0f-b86d9dc1786c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n"
     ]
    }
   ],
   "source": [
    "print(len(humps_per_sublist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc6ca854-5647-4a08-8a39-f45056acb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyMetric(nn.Module):\n",
    "    def forward(self, predictions, ground_truth):\n",
    "        predictions = torch.tensor(predictions)\n",
    "        ground_truth = torch.tensor(ground_truth)\n",
    "        correct = torch.eq(predictions, ground_truth).sum()\n",
    "        accuracy = correct.float() / ground_truth.size(0)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51681463-6dc3-4bb5-b35b-bcedcc61cb25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrecisionMetric(nn.Module):\n",
    "    # Precision: TP / (TP + FP)\n",
    "    def forward(self, predictions, ground_truth):\n",
    "        predictions = torch.tensor(predictions)\n",
    "        ground_truth = torch.tensor(ground_truth)\n",
    "        true_positive = torch.logical_and(predictions == 1, ground_truth == 1).sum()\n",
    "        predicted_positive = (predictions == 1).sum()\n",
    "        precision = true_positive.float() / predicted_positive if predicted_positive != 0 else torch.tensor(0.)\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fed45af-22ef-4f87-bd10-af5210a4fe16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecallMetric(nn.Module):\n",
    "    # Recall: TP / (TP + FN)\n",
    "    def forward(self, predictions, ground_truth):\n",
    "        predictions = torch.tensor(predictions)\n",
    "        ground_truth = torch.tensor(ground_truth)\n",
    "        true_positive = torch.logical_and(predictions == 1, ground_truth == 1).sum()\n",
    "        actual_positive = (ground_truth == 1).sum()\n",
    "        recall = true_positive.float() / actual_positive if actual_positive != 0 else torch.tensor(0.)\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e80bf2a3-a0c9-4cce-97ec-fe003d4d83de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class F1ScoreMetric(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.precision_metric = PrecisionMetric()\n",
    "        self.recall_metric = RecallMetric()\n",
    "    \n",
    "    def forward(self, predictions, ground_truth):\n",
    "        precision = self.precision_metric(predictions, ground_truth)\n",
    "        recall = self.recall_metric(predictions, ground_truth)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else torch.tensor(0.)\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a8fc16f-0d67-4076-8e60-f986cf93f48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = [[0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 1, 1, 0]]\n",
    "ground_truth = [[0, 0, 0, 1, 1, 1, 0], [0, 0, 0, 1, 1, 1, 0]]\n",
    "\n",
    "metric = AccuracyMetric()\n",
    "precision_metric = PrecisionMetric()\n",
    "recall_metric = RecallMetric()\n",
    "f1_score_metric = F1ScoreMetric()\n",
    "\n",
    "accuracy = metric(predictions, ground_truth)\n",
    "precision = precision_metric(predictions, ground_truth)\n",
    "recall = recall_metric(predictions, ground_truth)\n",
    "f1_score = f1_score_metric(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c739c5a6-2708-4606-8983-e1e967efd087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428656578064\n",
      "Precision: 1.0\n",
      "Recall: 0.6666666865348816\n",
      "F1 Score: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy.item())\n",
    "print(\"Precision:\", precision.item())\n",
    "print(\"Recall:\", recall.item())\n",
    "print(\"F1 Score:\", f1_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2708a30-f9d5-4ee2-b527-84f6b412540f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MaxAccuracyMetric(nn.Module):\n",
    "    def forward(self, predictions, ground_truth):\n",
    "        max_accuracies = []\n",
    "        for gt in ground_truth:\n",
    "            accuracies = []\n",
    "            for pred in predictions:\n",
    "                correct = torch.eq(pred, gt).sum()\n",
    "                accuracy = correct.float() / gt.size(0)\n",
    "                accuracies.append(accuracy)\n",
    "            max_accuracies.append(max(accuracies))\n",
    "        \n",
    "        return torch.tensor(max_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "080ad3a1-6eaa-40aa-97f7-c40e981ab304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracies: tensor([1.0000, 1.0000, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "predictions = [[0, 0, 0, 0, 1], [0, 0, 0, 1, 1]]\n",
    "ground_truth = [[0, 0, 0, 1, 1], [0, 0, 0, 0, 1], [0, 0, 0, 1, 0]]\n",
    "predictions = torch.tensor(predictions)\n",
    "ground_truth = torch.tensor(ground_truth)\n",
    "\n",
    "metric = MaxAccuracyMetric()\n",
    "\n",
    "max_accuracies = metric(predictions, ground_truth)\n",
    "print(\"Max Accuracies:\", max_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387a66f-d9ea-4be4-9b1f-55c498c08baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
