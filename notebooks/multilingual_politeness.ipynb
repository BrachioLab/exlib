{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import Pipeline\n",
    "from torch import Tensor \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import sentence_transformers\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO = \"shreyahavaldar/multilingual_politeness\"\n",
    "MODEL_REPO = \"shreyahavaldar/xlm-roberta-politeness\"\n",
    "\n",
    "def load_data():\n",
    "    hf_dataset = load_dataset(DATASET_REPO)\n",
    "    #convert to torch dataset\n",
    "    hf_dataset.set_format(type='torch')\n",
    "    return hf_dataset\n",
    "\n",
    "def load_model():\n",
    "    model = AutoModel.from_pretrained(MODEL_REPO)\n",
    "    #convert to pytorch model\n",
    "    torch_model = nn.Sequential(model, nn.Linear(model.config.hidden_size, 1))\n",
    "    model.to(device)\n",
    "    return torch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Alignment Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(nn.Module): \n",
    "    def __init__(self, model_name:str=\"distiluse-base-multilingual-cased\"): \n",
    "        super(Metric, self).__init__()\n",
    "        self.model = sentence_transformers.SentenceTransformer(model_name)\n",
    "        self.centroids = self.get_centroids()\n",
    "    \n",
    "    def get_centroids(self):\n",
    "        # read lexica files\n",
    "        languages = [\"english\", \"spanish\", \"chinese\", \"japanese\"]\n",
    "        lexica = {}\n",
    "        for l in languages:\n",
    "            filepath = f\"../src/exlib/utils/politeness_lexica/{l}_politelex.csv\"\n",
    "            lexica[l] = pd.read_csv(filepath)\n",
    "\n",
    "        # create centroids\n",
    "        all_centroids = {}        \n",
    "        for l in languages:\n",
    "            categories = lexica[l][\"CATEGORY\"].unique()\n",
    "            centroids = {}\n",
    "            for c in categories:\n",
    "                words = lexica[l][lexica[l][\"CATEGORY\"] == c][\"word\"].tolist()\n",
    "                embeddings = self.model.encode(words)\n",
    "                centroid = np.mean(embeddings, axis=0)\n",
    "                centroids[c] = centroid\n",
    "            assert len(categories) == len(centroids.keys())\n",
    "            all_centroids[l] = centroids\n",
    "            print(f\"Centroids for {l} created.\")\n",
    "        return all_centroids\n",
    "\n",
    "    # input: list of words\n",
    "    def calculate_single_group_alignment(self, group:list, language:str=\"english\"):\n",
    "        #find max avg cos sim between word embeddings and centroids\n",
    "        category_similarities = {}\n",
    "        centroids = self.centroids[language]\n",
    "        for category, centroid_emb in centroids.items():\n",
    "            #calculate cosine similarity\n",
    "            cos_sim = []\n",
    "            for word in group:\n",
    "                word_emb = self.model.encode(word)\n",
    "                cos_sim.append(np.dot(word_emb, centroid_emb) / (np.linalg.norm(word_emb) * np.linalg.norm(centroid_emb)))\n",
    "            avg_cos_sim = np.mean(cos_sim)\n",
    "            category_similarities[category] = avg_cos_sim\n",
    "        #return highest similarity score\n",
    "        return max(category_similarities.values())\n",
    "\n",
    "    def calculate_group_alignment(self, groups:list, language:str=\"english\"):\n",
    "        group_alignments = []\n",
    "        for group in groups:\n",
    "            group_alignments.append(self.calculate_single_group_alignment(group, language))\n",
    "        return group_alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Group Alignment Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids for english created.\n",
      "Centroids for spanish created.\n",
      "Centroids for chinese created.\n",
      "Centroids for japanese created.\n",
      "Group: ['dog', 'cat', 'fish'], Alignment: 0.5292773842811584\n",
      "Group: ['hello', 'goodbye', 'please'], Alignment: 0.7011184692382812\n",
      "Group: ['computer', 'laptop', 'phone'], Alignment: 0.4826013147830963\n",
      "Group: ['idiot', 'stupid', 'dumb'], Alignment: 0.7102837562561035\n",
      "Group: ['thank you', 'grateful', 'thanks'], Alignment: 0.9256609082221985\n"
     ]
    }
   ],
   "source": [
    "metric = Metric()\n",
    "sample_groups = [[\"dog\", \"cat\", \"fish\"], \n",
    "                [\"hello\", \"goodbye\", \"please\"], \n",
    "                [\"computer\", \"laptop\", \"phone\"], \n",
    "                [\"idiot\", \"stupid\", \"dumb\"], \n",
    "                [\"thank you\", \"grateful\", \"thanks\"]]\n",
    "alignments = metric.calculate_group_alignment(sample_groups)\n",
    "for group, alignment in zip(sample_groups, alignments):\n",
    "    print(f\"Group: {group}, Alignment: {alignment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtop",
   "language": "python",
   "name": "vtop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
