{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import Pipeline\n",
    "from torch import Tensor \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import sentence_transformers\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO = \"shreyahavaldar/multilingual_politeness\"\n",
    "MODEL_REPO = \"shreyahavaldar/xlm-roberta-politeness\"\n",
    "TOKENIZER_REPO = \"xlm-roberta-base\"\n",
    "\n",
    "def load_data():\n",
    "    hf_dataset = load_dataset(DATASET_REPO)\n",
    "    return hf_dataset\n",
    "\n",
    "def load_model():\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(MODEL_REPO)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "class PolitenessDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split, language=\"english\"):\n",
    "        dataset = load_dataset(DATASET_REPO)[split]\n",
    "        dataset = dataset.filter(lambda x: x[\"language\"] == language)\n",
    "        dataset = dataset.rename_column(\"politeness\", \"label\")\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = XLMRobertaTokenizer.from_pretrained(TOKENIZER_REPO)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[\"Utterance\"][idx]\n",
    "        label = self.dataset[\"label\"][idx]\n",
    "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"label\": torch.tensor(label)\n",
    "        }\n",
    "\n",
    "class PolitenessClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolitenessClassifier, self).__init__()\n",
    "        self.model = load_model()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids, attention_mask)\n",
    "        logits = outputs.logits\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample inference on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/570 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: That is why he is a ‘pretender’. He has never claimed to be a King - or a Kaiser, for that matter. He is in the same class as the Comte de Paris, who is not the King of France, but would be if the Bourbons were placed on a restored French throne.\n",
      "Politeness: -0.11096464097499847\n",
      "\n",
      "Text: Let's knock any 'EngVar' shenanigans on the head right away, shall we? The Manual of Style, as I understand it, makes it clear that the subject's national ties and own language set the course.\n",
      "Politeness: -0.4824700355529785\n",
      "\n",
      "Text: Thank you for your contributions. There are some conventions that apply to articles, and medical articles in particular. Secondary sources were available for the material, and should be cited to validate the medical information from the studies.\n",
      "Politeness: 1.5924450159072876\n",
      "\n",
      "Text: The conversion of tacit to explicit knowledge is seen in for example the bread making machine's case. In response to your question, culture is a broad term. I would like to narrow it down to organization culture.\n",
      "Politeness: 0.7522311210632324\n",
      "\n",
      "Text: It is definitely coming along. I broke out my own copy of Welding Principles and Applications but it is the fifth edition (different ISBN than the current Jefus reference). I found a reference for When using metals which melt at a low temperature, such as aluminum, it is important to be fast and accurate with the filler material placement.\n",
      "Politeness: 0.2505349814891815\n",
      "\n",
      "Text: Since its introduction in the early 90s, new computer video techniques have been introduced which the original AVI spec any compression technique which requires access to future video frame data beyond the current frame. I feel the same about this sentence. I've read and re-read it and I don't understand what it is trying to communicate.\n",
      "Politeness: -0.16643919050693512\n",
      "\n",
      "Text: The following comments are included in maintenance tags in the article and related edit comments. I am copying them here, as they seem to constitute de facto Talk page contributions.\n",
      "Politeness: 0.19039611518383026\n",
      "\n",
      "Text: Interview with Ninomiya Kazunari(Letters From Iwo Jima Paris Press Conference held on February 14, 2007) by JaME. Published October 28, 2007. Eastwood epic at the Berlin Film Festival by David Gordon Smith, February 13, 2007 SMAP's Kimutaku a different breed of idol by Philip Brasor.\n",
      "Politeness: 0.3310365080833435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = PolitenessDataset(\"train\")\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model = PolitenessClassifier()\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(dataloader): \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    utterances = [dataset.tokenizer.decode(input_id, skip_special_tokens=True) for input_id in input_ids]\n",
    "    for utterance, label in zip(utterances, output):\n",
    "        print(\"Text: {}\\nPoliteness: {}\\n\".format(utterance, label.item()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Alignment Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(nn.Module): \n",
    "    def __init__(self, model_name:str=\"distiluse-base-multilingual-cased\"): \n",
    "        super(Metric, self).__init__()\n",
    "        self.model = sentence_transformers.SentenceTransformer(model_name)\n",
    "        self.centroids = self.get_centroids()\n",
    "    \n",
    "    def get_centroids(self):\n",
    "        # read lexica files\n",
    "        languages = [\"english\", \"spanish\", \"chinese\", \"japanese\"]\n",
    "        lexica = {}\n",
    "        for l in languages:\n",
    "            filepath = f\"../src/exlib/utils/politeness_lexica/{l}_politelex.csv\"\n",
    "            lexica[l] = pd.read_csv(filepath)\n",
    "\n",
    "        # create centroids\n",
    "        all_centroids = {}        \n",
    "        for l in languages:\n",
    "            categories = lexica[l][\"CATEGORY\"].unique()\n",
    "            centroids = {}\n",
    "            for c in categories:\n",
    "                words = lexica[l][lexica[l][\"CATEGORY\"] == c][\"word\"].tolist()\n",
    "                embeddings = self.model.encode(words)\n",
    "                centroid = np.mean(embeddings, axis=0)\n",
    "                centroids[c] = centroid\n",
    "            assert len(categories) == len(centroids.keys())\n",
    "            all_centroids[l] = centroids\n",
    "            print(f\"Centroids for {l} created.\")\n",
    "        return all_centroids\n",
    "\n",
    "    # input: list of words\n",
    "    def calculate_single_group_alignment(self, group:list, language:str=\"english\"):\n",
    "        #find max avg cos sim between word embeddings and centroids\n",
    "        category_similarities = {}\n",
    "        centroids = self.centroids[language]\n",
    "        for category, centroid_emb in centroids.items():\n",
    "            #calculate cosine similarity\n",
    "            cos_sim = []\n",
    "            for word in group:\n",
    "                word_emb = self.model.encode(word)\n",
    "                cos_sim.append(np.dot(word_emb, centroid_emb) / (np.linalg.norm(word_emb) * np.linalg.norm(centroid_emb)))\n",
    "            avg_cos_sim = np.mean(cos_sim)\n",
    "            category_similarities[category] = avg_cos_sim\n",
    "        #return highest similarity score\n",
    "        return max(category_similarities.values())\n",
    "\n",
    "    def calculate_group_alignment(self, groups:list, language:str=\"english\"):\n",
    "        group_alignments = []\n",
    "        for group in groups:\n",
    "            group_alignments.append(self.calculate_single_group_alignment(group, language))\n",
    "        return group_alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Group Alignment Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids for english created.\n",
      "Centroids for spanish created.\n",
      "Centroids for chinese created.\n",
      "Centroids for japanese created.\n",
      "Group: ['dog', 'cat', 'fish'], Alignment: 0.5292773842811584\n",
      "Group: ['hello', 'goodbye', 'please'], Alignment: 0.7011184692382812\n",
      "Group: ['computer', 'laptop', 'phone'], Alignment: 0.4826013147830963\n",
      "Group: ['idiot', 'stupid', 'dumb'], Alignment: 0.7102837562561035\n",
      "Group: ['thank you', 'grateful', 'thanks'], Alignment: 0.9256609082221985\n"
     ]
    }
   ],
   "source": [
    "metric = Metric()\n",
    "sample_groups = [[\"dog\", \"cat\", \"fish\"], \n",
    "                [\"hello\", \"goodbye\", \"please\"], \n",
    "                [\"computer\", \"laptop\", \"phone\"], \n",
    "                [\"idiot\", \"stupid\", \"dumb\"], \n",
    "                [\"thank you\", \"grateful\", \"thanks\"]]\n",
    "alignments = metric.calculate_group_alignment(sample_groups)\n",
    "for group, alignment in zip(sample_groups, alignments):\n",
    "    print(f\"Group: {group}, Alignment: {alignment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtop",
   "language": "python",
   "name": "vtop"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
