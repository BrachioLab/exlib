{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047fdfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import exlib\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4518817-67b0-4bb2-b180-3d4cea118d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from exlib.datasets.massmaps import MassMapsConvnetForImageRegression\n",
    "model = MassMapsConvnetForImageRegression.from_pretrained(massmaps.MODEL_REPO)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f324f5d-a9ed-40ff-b026-d0ea8e7f9465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from exlib.datasets import massmaps\n",
    "train_dataset = load_dataset(massmaps.DATASET_REPO, split='train')\n",
    "val_dataset = load_dataset(massmaps.DATASET_REPO, split='validation')\n",
    "test_dataset = load_dataset(massmaps.DATASET_REPO, split='test')\n",
    "train_dataset.set_format('torch', columns=['input', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7932ffc7-2693-4edf-b4ac-11172d7483b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "\n",
    "from skimage.segmentation import watershed, quickshift\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from exlib.explainers.common import convert_idx_masks_to_bool\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class MassMapsWatershed(nn.Module):\n",
    "    def apply_watershed(self, image, compactness=0):\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        distance = ndimage.distance_transform_edt(image)\n",
    "        coords = peak_local_max(distance, min_distance=10, labels=image)\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndimage.label(mask)\n",
    "        raw_labels = watershed(-distance, markers, mask=image,\n",
    "                               compactness=compactness)\n",
    "        return raw_labels\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        input: images (N, C=1, H, W)\n",
    "        output: daf_preds (N, H, W)\n",
    "        \"\"\"\n",
    "        daf_preds = []\n",
    "        for image in images:\n",
    "            segment_mask = torch.tensor(self.apply_watershed(image[0].cpu().numpy())).to(images.device)\n",
    "            masks_bool = convert_idx_masks_to_bool(segment_mask[None])\n",
    "            daf_preds.append(masks_bool)\n",
    "        daf_preds = torch.nn.utils.rnn.pad_sequence(daf_preds, batch_first=True)\n",
    "        return daf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610c294b-792e-4df2-875e-09a37b65fb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 66, 66]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X, y = train_dataset[0:2]['input'], train_dataset[0:2]['label']\n",
    "X,y = [torch.tensor(a).to(device) for a in (X,y)]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f35e328-a6bd-4e7e-b491-3a0b661061ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75, 66, 66])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watershed_dafer = MassMapsWatershed().to(device)\n",
    "zp = watershed_dafer(X)\n",
    "zp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "738863ad-0c42-4f26-a065-8bf67e18fc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6746, 0.2792], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exlib.datasets.massmaps import MassMapsMetrics\n",
    "massmaps_metrics = MassMapsMetrics()\n",
    "massmaps_metrics(zp, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "437c3f2f-6ab7-4f85-8ac2-b52a2f64dedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad2381ff-22be-421e-9877-29adda4432ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 66, 66]) torch.Size([5, 2])\n",
      "tensor([[0.1919, 0.9655],\n",
      "        [0.1325, 1.1280],\n",
      "        [0.2477, 0.5534],\n",
      "        [0.3207, 0.7607],\n",
      "        [0.0986, 1.1716]], device='cuda:0', grad_fn=<AddmmBackward0>) tensor([[0.1846, 0.9884],\n",
      "        [0.1037, 1.1905],\n",
      "        [0.2908, 0.4728],\n",
      "        [0.2787, 0.7530],\n",
      "        [0.1245, 1.1571]], device='cuda:0') tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    X = batch['input'].to(device)\n",
    "    y = batch['label'].to(device)\n",
    "    print(X.shape, y.shape)\n",
    "    out = model(X)\n",
    "    loss = F.mse_loss(out, y)\n",
    "    print(out, y, loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dabd58-7332-487b-94c9-6bf506454791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
