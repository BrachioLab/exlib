{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047fdfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import exlib\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4518817-67b0-4bb2-b180-3d4cea118d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from exlib.datasets.massmaps import MassMapsConvnetForImageRegression\n",
    "model = MassMapsConvnetForImageRegression.from_pretrained(massmaps.MODEL_REPO) # BrachioLab/massmaps-conv\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f324f5d-a9ed-40ff-b026-d0ea8e7f9465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from exlib.datasets import massmaps\n",
    "train_dataset = load_dataset(massmaps.DATASET_REPO, split='train') # BrachioLab/massmaps-cosmogrid-100k\n",
    "val_dataset = load_dataset(massmaps.DATASET_REPO, split='validation')\n",
    "test_dataset = load_dataset(massmaps.DATASET_REPO, split='test')\n",
    "train_dataset.set_format('torch', columns=['input', 'label'])\n",
    "val_dataset.set_format('torch', columns=['input', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7932ffc7-2693-4edf-b4ac-11172d7483b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "\n",
    "from skimage.segmentation import watershed, quickshift\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from exlib.explainers.common import convert_idx_masks_to_bool\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class MassMapsWatershed(nn.Module):\n",
    "    def apply_watershed(self, image, compactness=0):\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        distance = ndimage.distance_transform_edt(image)\n",
    "        coords = peak_local_max(distance, min_distance=10, labels=image)\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers, _ = ndimage.label(mask)\n",
    "        raw_labels = watershed(-distance, markers, mask=image,\n",
    "                               compactness=compactness)\n",
    "        return raw_labels\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        input: images (N, C=1, H, W)\n",
    "        output: daf_preds (N, H, W)\n",
    "        \"\"\"\n",
    "        daf_preds = []\n",
    "        for image in images:\n",
    "            segment_mask = torch.tensor(self.apply_watershed(image[0].cpu().numpy())).to(images.device)\n",
    "            masks_bool = convert_idx_masks_to_bool(segment_mask[None])\n",
    "            daf_preds.append(masks_bool)\n",
    "        daf_preds = torch.nn.utils.rnn.pad_sequence(daf_preds, batch_first=True)\n",
    "        return daf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "610c294b-792e-4df2-875e-09a37b65fb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 66, 66]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X, y = train_dataset[0:2]['input'], train_dataset[0:2]['label']\n",
    "X,y = [torch.tensor(a).to(device) for a in (X,y)]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f35e328-a6bd-4e7e-b491-3a0b661061ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75, 66, 66])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watershed_dafer = MassMapsWatershed().to(device)\n",
    "zp = watershed_dafer(X)\n",
    "zp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "738863ad-0c42-4f26-a065-8bf67e18fc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6746, 0.2792], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exlib.datasets.massmaps import MassMapsMetrics\n",
    "massmaps_metrics = MassMapsMetrics()\n",
    "metrics_scores = massmaps_metrics(zp, X)\n",
    "metrics_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "437c3f2f-6ab7-4f85-8ac2-b52a2f64dedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad2381ff-22be-421e-9877-29adda4432ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384df7e4ce2443e2a2a5108c69aa7f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model.eval()\n",
    "mse_loss_all = 0\n",
    "total = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    X = batch['input'].to(device)\n",
    "    y = batch['label'].to(device)\n",
    "    out = model(X)\n",
    "    loss = F.mse_loss(out, y, reduction='none')\n",
    "    mse_loss_all = mse_loss_all + loss.sum(0)\n",
    "    total += X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8dabd58-7332-487b-94c9-6bf506454791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0050, 0.0112], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_avg = mse_loss_all / total\n",
    "loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95b83ca3-304c-40df-9aab-26f0ecaa2bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omega_m loss 0.0050, sigma_8 loss 0.0112, avg loss 0.0081\n"
     ]
    }
   ],
   "source": [
    "print(f'Omega_m loss {loss_avg[0].item():.4f}, sigma_8 loss {loss_avg[1].item():.4f}, avg loss {loss_avg.mean().item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb67b3-829b-4842-a727-02f3e336943e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
