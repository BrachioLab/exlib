{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77da3d13-370e-4923-ad38-45e386ecb42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow_hotfix\n",
    "import torch\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import exlib\n",
    "import math\n",
    "\n",
    "from datasets import load_dataset\n",
    "from collections import namedtuple\n",
    "from exlib.datasets.pretrain import setup_model_config, get_dataset, get_dataset, setup_model_config\n",
    "from exlib.datasets.dataset_preprocess_raw import create_train_dataloader_raw, create_test_dataloader_raw, create_test_dataloader\n",
    "from exlib.datasets.informer_models import InformerConfig, InformerForSequenceClassification\n",
    "from tqdm.auto import tqdm\n",
    "pa.PyExtensionType.set_auto_load(True)\n",
    "pyarrow_hotfix.uninstall()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734df5cc-e41d-4960-abd8-157dd1928114",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f776b1-b426-49fa-a757-7dbb0154e5da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"BrachioLab/supernova-timeseries\")\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c26cae-5df4-415c-8c7a-eecb2b742807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['objid', 'times_wv', 'target', 'label', 'redshift'],\n",
       "    num_rows: 6274\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b36011f-52e5-4e8a-8638-59a3023f1c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['objid', 'times_wv', 'target', 'label', 'redshift'],\n",
       "    num_rows: 782\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d050b6-7ee6-41f6-afde-540b0f4ed993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['objid', 'times_wv', 'target', 'label', 'redshift'],\n",
       "    num_rows: 792\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b8c8a-f919-4a7b-b50c-49cbf00ad320",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324aae68-941b-482b-a385-c956165a721e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 14\n",
      "Using Fourier PE\n",
      "classifier dropout: 0.2\n",
      "original dataset size: 792\n",
      "remove nans dataset size: 792\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = InformerForSequenceClassification.from_pretrained(\"BrachioLab/supernova-classification\")\n",
    "model = model.to(device)\n",
    "config = InformerConfig.from_pretrained(\"BrachioLab/supernova-classification\")\n",
    "test_dataloader = create_test_dataloader(\n",
    "    config=config,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=5,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f88110-a681-4c31-8124-73a1b4880456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac520c0ca1143e8b9ae0f80adb0b328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7967171717171717\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    alignment_scores_all = []\n",
    "    for bi, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "        outputs = model(**batch)\n",
    "        y_true.extend(batch['labels'].cpu().numpy())\n",
    "        y_pred.extend(torch.argmax(outputs.logits, dim=2).squeeze().cpu().numpy())\n",
    "# model prediction\n",
    "print(f\"accuracy: {sum([1 for i, j in zip(y_true, y_pred) if i == j]) / len(y_true)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a640b89-0e66-4d3d-8aa1-779149fee59a",
   "metadata": {},
   "source": [
    "### Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf6d6f9-66b8-4348-9fcc-9a5e33c24bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size: 792\n",
      "remove nans dataset size: 792\n"
     ]
    }
   ],
   "source": [
    "config = InformerConfig.from_pretrained(\"BrachioLab/supernova-classification\")\n",
    "test_dataloader = create_test_dataloader_raw(\n",
    "    config=config,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=25,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0627f11d-5a0a-4e17-8066-fddd9b075c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_by_wavelength(times, fluxes, errors, wavelengths, title, bi, j):\n",
    "    unique_wavelengths = sorted(set(wavelengths))\n",
    "    color_map = plt.get_cmap('rainbow')\n",
    "    colors = color_map(np.linspace(0, 1, len(unique_wavelengths)))\n",
    "    wavelength_to_color = {w: c for w, c in zip(unique_wavelengths, colors)}\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    for wavelength in unique_wavelengths:\n",
    "        indices = [i for i, w in enumerate(wavelengths) if w == wavelength]\n",
    "        plt.errorbar([times[i] for i in indices], [fluxes[i] for i in indices], yerr=[errors[i] for i in indices],\n",
    "                     fmt='o', color=wavelength_to_color[wavelength], capsize=5, label=f'{wavelength}')\n",
    "    #plt.xlabel('Time')\n",
    "    #plt.ylabel('Flux')\n",
    "    #plt.title(title, fontsize=10)\n",
    "    \n",
    "    plt.legend(title=\"Wavelengths\", loc='upper right', fontsize='small', title_fontsize='small')\n",
    "    plt.savefig(f'groups_example/plot_org_{bi}_{j}.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.grid(True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6ad0d9c-f42f-4454-bf85-6aa8f3a52dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70621b6524954bf0a1b9f47c9f551b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset sample\n",
    "with torch.no_grad():\n",
    "    alignment_scores_all = []\n",
    "    for bi, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # prediction\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "        \n",
    "        times_wv_column = batch['past_time_features'].to('cpu')\n",
    "        target_column = batch['past_values'].to('cpu')\n",
    "        x_column = np.concatenate((times_wv_column, target_column), axis=2) # time, wavelength, flux, flux_error\n",
    "        time_values = x_column[:, :, 0].tolist() # time_values is from 0 to 1, and if it is less than 300 random values\n",
    "        wavelength_values = x_column[:, :, 1].tolist()\n",
    "        flux_values = x_column[:, :, 2].tolist()\n",
    "        flux_error_values = x_column[:, :, 3].tolist()\n",
    "        \n",
    "        valid_time_values_batch = []\n",
    "        valid_wavelength_values_batch = []\n",
    "        valid_flux_values_batch = []\n",
    "        valid_flux_error_values_batch = []\n",
    "        zeros_batch = []\n",
    "        valid_length_batch = []\n",
    "        pred_groups_batch = []\n",
    "        for idx, time_list in enumerate(time_values):\n",
    "            valid_length = next((j for j in range(1, len(time_list)) if time_list[j] <= time_list[j-1]), len(time_list))\n",
    "            valid_time_values_batch.append(time_list[:valid_length])\n",
    "            valid_wavelength_values_batch.append(wavelength_values[idx][:valid_length])\n",
    "            valid_flux_values_batch.append(flux_values[idx][:valid_length])\n",
    "            valid_flux_error_values_batch.append(flux_error_values[idx][:valid_length])\n",
    "            valid_length_batch.append(valid_length)\n",
    "\n",
    "        if bi == 0:\n",
    "            for j in range(len(valid_time_values_batch)):\n",
    "                if j == 24:\n",
    "                    plot_data_by_wavelength(valid_time_values_batch[j], valid_flux_values_batch[j], \n",
    "                                            valid_flux_error_values_batch[j], valid_wavelength_values_batch[j],\n",
    "                                            'Flux vs. Time with Error Bars by Wavelength', bi, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f51151e-a6d5-43db-b9d4-1d7ab68eea0f",
   "metadata": {},
   "source": [
    "### Alignment score without ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3400cba2-9b79-400b-adbe-8b272fdd0de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size: 792\n",
      "remove nans dataset size: 792\n"
     ]
    }
   ],
   "source": [
    "config = InformerConfig.from_pretrained(\"BrachioLab/supernova-classification\")\n",
    "test_dataloader = create_test_dataloader_raw(\n",
    "    config=config,\n",
    "    dataset=test_dataset,\n",
    "    batch_size=25,\n",
    "    compute_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85915d43-4975-4bcf-83e1-663eae0b6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "chunk_size = 30\n",
    "def baseline(valid_length):\n",
    "    num_groups = valid_length // chunk_size\n",
    "    if valid_length % chunk_size != 0:\n",
    "        num_groups += 1\n",
    "    pred_groups = []\n",
    "    for group_idx in range(num_groups):\n",
    "        start_index = group_idx * chunk_size\n",
    "        end_index = min((group_idx + 1) * chunk_size, valid_length)\n",
    "        group_list = [1 if start_index <= i < end_index else 0 for i in range(valid_length)]\n",
    "        pred_groups.append(group_list)\n",
    "    return pred_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ac9788-b987-4057-bb9c-2175f174c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_regression(x, y, min_len=3):\n",
    "    if not x or len(x) < min_len:\n",
    "        return (1000, 1000)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    return (slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9aee587-65d6-4310-b394-3af91ccf86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_f(eps, error, time):\n",
    "    if not error or not time:\n",
    "        return 0\n",
    "    time_range = max(time) - min(time)\n",
    "    if time_range == 0:\n",
    "        return 0\n",
    "    thres = eps * (sum(error)/len(error)) / (time_range)\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a68bedca-928c-4497-ba94-df02e826fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alignment_scores_for_group(times, wavelengths, fluxes, errors, groups, eps=1, min_len=3, window_size=50, step_size=25):\n",
    "    group_time = [times[i] for i, value in enumerate(pred_groups_batch[j][k]) if value == 1]\n",
    "    group_slope = []\n",
    "    group_intercept = []\n",
    "    group_threshold = []\n",
    "    group_lc = []\n",
    "    group_p = []\n",
    "    group_f = []\n",
    "    #chunk_time = [[time, time + window_size] for time in crop_time_wv]\n",
    "    chunk_time = []\n",
    "    current_start = group_time[0]\n",
    "    while current_start + window_size < group_time[-1]:\n",
    "        chunk_time.append([current_start, current_start + window_size])\n",
    "        current_start += step_size\n",
    "    chunk_time.append([current_start, current_start + window_size])\n",
    "    \n",
    "    for m in range(len(unique_wavelengths)):\n",
    "        chunk_f = 0\n",
    "        chunk_p = 0\n",
    "        crop_time_wv = [time for time in time_wv[unique_wavelengths[m]] if time in group_time]\n",
    "        \n",
    "        crop_flux_wv = [flux_wv[unique_wavelengths[m]][i] for i, time in enumerate(time_wv[unique_wavelengths[m]]) if time in group_time]\n",
    "        crop_error_wv = [error_wv[unique_wavelengths[m]][i] for i, time in enumerate(time_wv[unique_wavelengths[m]]) if time in group_time]\n",
    "        slope, intercept = perform_linear_regression(crop_time_wv, crop_flux_wv)\n",
    "        group_slope.append(slope)\n",
    "        group_intercept.append(intercept)\n",
    "        threshold = threshold_f(eps, crop_error_wv, crop_time_wv)\n",
    "        group_threshold.append(threshold)\n",
    "        p_in = 0\n",
    "        f_in = 0\n",
    "        for n in range(len(chunk_time)):\n",
    "            chunk_time_wv = [time for time in crop_time_wv if chunk_time[n][0] <= time <= chunk_time[n][1]]\n",
    "            indices = [i for i, time in enumerate(crop_time_wv) if time in chunk_time_wv]\n",
    "            chunk_flux_wv = [crop_flux_wv[i] for i in indices]\n",
    "            chunk_error_wv = [crop_error_wv[i] for i in indices]\n",
    "            chunk_slope = perform_linear_regression(chunk_time_wv, chunk_flux_wv)\n",
    "            chunk_threshold = threshold_f(eps, chunk_error_wv, chunk_time_wv)\n",
    "            if chunk_time_wv:\n",
    "                p_in += 1\n",
    "                \n",
    "            f_in_chunk = 0\n",
    "            if len(chunk_time_wv) >= min_len:\n",
    "                for time, flux, error in zip(chunk_time_wv, chunk_flux_wv, chunk_error_wv):\n",
    "                    predicted_flux = group_slope[m] * time + group_intercept[m]\n",
    "                    lower_bound = flux - (eps*error)\n",
    "                    upper_bound = flux + (eps*error)\n",
    "                    if lower_bound <= predicted_flux <= upper_bound:\n",
    "                        f_in_chunk += 1\n",
    "            if f_in_chunk == len(chunk_time_wv):\n",
    "                f_in += 1\n",
    "            \n",
    "        group_f.append(f_in / len(chunk_time))\n",
    "        group_p.append(p_in / len(chunk_time))\n",
    "    group_lc = []\n",
    "    for p, f in zip(group_p, group_f):\n",
    "        group_lc.append(p * f)\n",
    "\n",
    "    if all(slope <= threshold for slope, threshold in zip(group_slope, group_threshold)):\n",
    "        max_lc = max(group_lc)\n",
    "        idx = torch.Tensor(group_lc).argmax()\n",
    "        #print(\"wavelength 1\", unique_wavelengths[idx])\n",
    "    else:\n",
    "        max_lc = max(lc for slope, lc, threshold in zip(group_slope, group_lc, group_threshold) if slope > threshold)\n",
    "        \n",
    "        idx = torch.Tensor(group_lc).argmax()\n",
    "        #print(\"wavelength 2\", unique_wavelengths[idx])\n",
    "    return(max_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "098868a3-6d33-4d5d-8911-933ed7c44d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flux_time_with_error_bars_group(times, wavelengths, fluxes, errors, pred_groups, unique_wavelengths, wavelength_to_color, bi, j, k, max_lc):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    title = 'Flux vs. Time with Error Bars by Wavelength (Expert Alignment: {:.2f})'.format(max_lc)\n",
    "    #ax.set_title(title, fontsize=10)\n",
    "    \n",
    "    for wavelength in unique_wavelengths:\n",
    "        indices = [i for i, w in enumerate(wavelengths) if w == wavelength]\n",
    "        ax.errorbar([times[i] for i in indices], [fluxes[i] for i in indices], yerr=[errors[i] for i in indices],\n",
    "                    fmt='o', color=wavelength_to_color[wavelength], capsize=5, label=f'{wavelength}')\n",
    "    \n",
    "    # Highlight expert alignment groups\n",
    "    for i in range(len(pred_groups[j][k])):\n",
    "        if pred_groups[j][k][i] == 1:\n",
    "            if i == 0 or pred_groups[j][k][i-1] == 0:  # Start of a new span\n",
    "                start_time = times[i]\n",
    "            if i == len(pred_groups[j][k]) - 1 or pred_groups[j][k][i+1] == 0:  # End of a span\n",
    "                end_time = times[i]\n",
    "                ax.axvspan(start_time, end_time, color='gray', alpha=0.3)  # Adding the vertical span\n",
    "    \n",
    "    #ax.set_xlabel('Time')\n",
    "    #ax.set_ylabel('Flux')\n",
    "    ax.legend(title=\"Wavelengths\", loc='upper right', fontsize='small', title_fontsize='small')\n",
    "    ax.grid(False)  # Disable grid explicitly if needed\n",
    "    plt.savefig(f'groups_example/plot_{bi}_{j}_{k}.png', format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ad93411-395d-4358-81b8-02d4fdf94218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c05472fc9b4a6c872f3105017729bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.32807599748179966 4899\n"
     ]
    }
   ],
   "source": [
    "# alignment score - without ground truth\n",
    "with torch.no_grad():\n",
    "    alignment_scores_all = []\n",
    "    for bi, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # prediction\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "            \n",
    "        times_wv_column = batch['past_time_features'].to('cpu')\n",
    "        target_column = batch['past_values'].to('cpu')\n",
    "        x_column = np.concatenate((times_wv_column, target_column), axis=2) # time, wavelength, flux, flux_error\n",
    "        time_values = x_column[:, :, 0].tolist() # time_values is from 0 to 1, and if it is less than 300 random values\n",
    "        wavelength_values = x_column[:, :, 1].tolist()\n",
    "        flux_values = x_column[:, :, 2].tolist()\n",
    "        flux_error_values = x_column[:, :, 3].tolist()\n",
    "        \n",
    "        # predicted group\n",
    "        valid_time_values_batch = []\n",
    "        valid_wavelength_values_batch = []\n",
    "        valid_flux_values_batch = []\n",
    "        valid_flux_error_values_batch = []\n",
    "        valid_length_batch = []\n",
    "        pred_groups_batch = []\n",
    "        \n",
    "        for idx, time_list in enumerate(time_values):\n",
    "            valid_length = next((j for j in range(1, len(time_list)) if time_list[j] <= time_list[j-1]), len(time_list))\n",
    "            valid_time_values_batch.append(time_list[:valid_length])\n",
    "            valid_wavelength_values_batch.append(wavelength_values[idx][:valid_length])\n",
    "            valid_flux_values_batch.append(flux_values[idx][:valid_length])\n",
    "            valid_flux_error_values_batch.append(flux_error_values[idx][:valid_length])\n",
    "            valid_length_batch.append(valid_length)\n",
    "            \n",
    "            pred_groups = baseline(valid_length)\n",
    "            pred_groups_batch.append(pred_groups)\n",
    "            # pred_groups_batch: batch_size * pred_group_num * valid_length\n",
    "\n",
    "        for j in range(len(valid_time_values_batch)): # j: batch size\n",
    "            times = valid_time_values_batch[j]\n",
    "            fluxes = valid_flux_values_batch[j]\n",
    "            errors = valid_flux_error_values_batch[j]\n",
    "            wavelengths = valid_wavelength_values_batch[j]\n",
    "            unique_wavelengths = sorted(set(wavelengths))\n",
    "            num_unique_wavelengths = len(unique_wavelengths)\n",
    "            time_wv = {wavelength: [] for wavelength in unique_wavelengths}\n",
    "            flux_wv = {wavelength: [] for wavelength in unique_wavelengths}\n",
    "            error_wv = {wavelength: [] for wavelength in unique_wavelengths}\n",
    "            \n",
    "            for time, flux, error, wavelength in zip(times, fluxes, errors, wavelengths):\n",
    "                time_wv[wavelength].append(time)\n",
    "                flux_wv[wavelength].append(flux)\n",
    "                error_wv[wavelength].append(error)\n",
    "            unique_wavelengths = sorted(set(wavelengths))\n",
    "            color_map = plt.get_cmap('rainbow')\n",
    "            colors = color_map(np.linspace(0, 1, len(unique_wavelengths)))\n",
    "            wavelength_to_color = {w: c for w, c in zip(unique_wavelengths, colors)}\n",
    "\n",
    "            eps = 1\n",
    "            min_len = 3\n",
    "            window_size = 50\n",
    "            step_size = int(window_size / 2)\n",
    "            for k in range(len(pred_groups_batch[j])): # k: number of group\n",
    "                max_lc = calculate_alignment_scores_for_group(times, wavelengths, fluxes, errors, pred_groups_batch[j], eps, min_len, window_size, step_size)\n",
    "                alignment_scores_all.append(max_lc)\n",
    "                # save plots\n",
    "                if bi == 0:\n",
    "                    if k == 8:\n",
    "                        plot_flux_time_with_error_bars_group(times, wavelengths, fluxes, errors, pred_groups_batch, unique_wavelengths, wavelength_to_color, bi, j, k, max_lc)\n",
    "                    \n",
    "print(\"score:\", sum(alignment_scores_all)/len(alignment_scores_all), len(alignment_scores_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71848d9-0370-4e3a-b977-aec99cce34ab",
   "metadata": {},
   "source": [
    "### Alignment score with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7da50f61-ae8e-4db9-978f-cea8235943c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6a130ab9c74f748b1e725d10cbf880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ground truth\n",
    "with torch.no_grad():\n",
    "    alignment_scores_all = []\n",
    "    for bi, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # prediction\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "        \n",
    "        times_wv_column = batch['past_time_features'].to('cpu')\n",
    "        target_column = batch['past_values'].to('cpu')\n",
    "        x_column = np.concatenate((times_wv_column, target_column), axis=2) # time, wavelength, flux, flux_error\n",
    "        time_values = x_column[:, :, 0].tolist() # time_values is from 0 to 1, and if it is less than 300 random values\n",
    "        #print(time_values)\n",
    "        wavelength_values = x_column[:, :, 1].tolist()\n",
    "        flux_values = x_column[:, :, 2].tolist()\n",
    "        flux_error_values = x_column[:, :, 3].tolist()\n",
    "        \n",
    "        valid_time_values_batch = []\n",
    "        valid_wavelength_values_batch = []\n",
    "        valid_flux_values_batch = []\n",
    "        valid_flux_error_values_batch = []\n",
    "        zeros_batch = []\n",
    "        valid_length_batch = []\n",
    "        pred_groups_batch = []\n",
    "        for idx, time_list in enumerate(time_values):\n",
    "            valid_length = next((j for j in range(1, len(time_list)) if time_list[j] <= time_list[j-1]), len(time_list))\n",
    "            valid_time_values_batch.append(time_list[:valid_length])\n",
    "            valid_wavelength_values_batch.append(wavelength_values[idx][:valid_length])\n",
    "            valid_flux_values_batch.append(flux_values[idx][:valid_length])\n",
    "            valid_flux_error_values_batch.append(flux_error_values[idx][:valid_length])\n",
    "            valid_length_batch.append(valid_length)\n",
    "\n",
    "        if bi == 0:\n",
    "            int_time_values_batch = []\n",
    "            window_size = 15\n",
    "            window_time_values_batch = []\n",
    "            window_flux_values_batch = []\n",
    "            for j in range(len(valid_time_values_batch)):\n",
    "                unique_wavelengths = sorted(set(valid_wavelength_values_batch[j]))\n",
    "                #print(unique_wavelengths)\n",
    "                start = math.floor(valid_time_values_batch[j][0])\n",
    "                end = math.ceil(valid_time_values_batch[j][-1])\n",
    "                int_time_values_batch.append(list(range(start, end + 1)))\n",
    "                window_time_values_batch.append([[int_time_values_batch_j[i], int_time_values_batch_j[i + window_size - 1]] for i in range(len(int_time_values_batch_j) - window_size + 1)])\n",
    "                #print(len(window_time_values_batch), len(window_time_values_batch[j]), window_time_values_batch[j][0])\n",
    "                \n",
    "                batch_windows = []\n",
    "                for k in range(len(window_time_values_batch[j])):\n",
    "                    window_wavelengths = [0] * len(unique_wavelengths)\n",
    "                    batch_windows.append(window_wavelengths)\n",
    "                window_flux_values_batch.append(batch_windows)\n",
    "                #print(len(window_flux_values_batch), len(window_flux_values_batch[j]), len(window_flux_values_batch[j][0]))\n",
    "\n",
    "                for k in range(len(unique_wavelengths)):\n",
    "                    target_wavelength = unique_wavelengths[k]\n",
    "                    indices_with_target_wavelength = [i for i, wavelength in enumerate(valid_wavelength_values_batch[j]) if wavelength == target_wavelength]\n",
    "                    #print(\"Indices with wavelength\", target_wavelength, \":\", indices_with_target_wavelength)\n",
    "            #print(len(window_time_values_batch), len(window_time_values_batch[j]), window_time_values_batch[j][0])\n",
    "            #print(len(window_flux_values_batch), len(window_flux_values_batch[j]), len(window_flux_values_batch[j][0]))\n",
    "            #print(window_flux_values_batch[j])\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "648bde41-786b-435d-a413-a5461265273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment score - with ground truth\n",
    "def process_group_pair(pred_group, true_group, device):\n",
    "    pred_groups = torch.tensor(pred_group, dtype=torch.float32).to(device)\n",
    "    true_groups = torch.tensor(true_group, dtype=torch.float32).to(device)\n",
    "    pred_groups_bool = pred_groups.to(torch.bool)\n",
    "    true_groups_bool = true_groups.to(torch.bool)\n",
    "    intersections = (pred_groups_bool.unsqueeze(1) & true_groups_bool.unsqueeze(0)).float().sum(dim=2)\n",
    "    unions = (pred_groups_bool.unsqueeze(1) | true_groups_bool.unsqueeze(0)).float().sum(dim=2)\n",
    "    ious = intersections / unions\n",
    "    ious = torch.nan_to_num(ious, nan=0.0)\n",
    "    max_iou, _ = torch.max(ious, dim=1)\n",
    "    avg_list = []\n",
    "    for col in range(pred_groups.size(1)):\n",
    "        mask = pred_groups[:, col] == 1\n",
    "        if torch.any(mask):\n",
    "            avg_iou = max_iou[mask].mean().item()\n",
    "        else:\n",
    "            avg_iou = 0\n",
    "        avg_list.append(avg_iou)\n",
    "    return avg_list\n",
    "\n",
    "def calculate_alignment_scores(pred_groups_batch, true_groups_batch, device):\n",
    "    alignment_scores = []\n",
    "    for i in range(len(pred_groups_batch)):\n",
    "        avg_list = process_group_pair(pred_groups_batch[i], true_groups_batch[i], device)\n",
    "        alignment_score = sum(avg_list) / len(avg_list) if avg_list else 0\n",
    "        alignment_scores.append(alignment_score)\n",
    "    return alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5ec811aa-5734-457f-8995-b7ca2205f7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8628aa4380114c67ad7c1e356208df0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average alignment score: 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    alignment_scores_all = []\n",
    "    for bi, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        # prediction\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"objid\"}\n",
    "        \n",
    "        times_wv_column = batch['past_time_features'].to('cpu')\n",
    "        target_column = batch['past_values'].to('cpu')\n",
    "        x_column = np.concatenate((times_wv_column, target_column), axis=2) # time, wavelength, flux, flux_error\n",
    "        time_values = x_column[:, :, 0].tolist() # time_values is from 0 to 1, and if it is less than 300 random values\n",
    "        \n",
    "        # predicted group\n",
    "        valid_time_values_batch = []\n",
    "        valid_length_batch = []\n",
    "        pred_groups_batch = []\n",
    "        for idx, time_list in enumerate(time_values):\n",
    "            valid_length = next((j for j in range(1, len(time_list)) if time_list[j] <= time_list[j-1]), len(time_list))\n",
    "            valid_time_values_batch.append(time_list[:valid_length])\n",
    "            \n",
    "            pred_groups = baseline(valid_length)\n",
    "            pred_groups_batch.append(pred_groups)\n",
    "            # pred_groups_batch: batch_size * pred_group_num * valid_length\n",
    "\n",
    "        # ground truth group - need to update\n",
    "        true_groups_batch = pred_groups_batch\n",
    "        #true_groups_batch = [[[0.0 for _ in sub_group] for sub_group in group] for group in pred_groups_batch]\n",
    "\n",
    "        # alignment score\n",
    "        alignment_scores = calculate_alignment_scores(pred_groups_batch, true_groups_batch, device)\n",
    "        alignment_scores_all.extend(alignment_scores)\n",
    "# all alignment score\n",
    "print(f\"average alignment score: {sum(alignment_scores_all) / len(alignment_scores_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8749434-b89f-431e-a545-25c5a2d44927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2325bc-efa3-4f75-b363-59ae13d4c7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
