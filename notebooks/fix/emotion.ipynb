{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install exlib\n",
    "# !pip install exlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import sentence_transformers\n",
    "\n",
    "import sys\n",
    "sys.path.append('/shared_data0/chaenyk/exlib/src')\n",
    "import exlib\n",
    "from exlib.utils.emotion_helper import project_points_onto_axes, load_emotions\n",
    "from exlib.datasets.emotion import load_data, load_model, EmotionDataset, EmotionClassifier, Metric, get_emotion_scores\n",
    "\n",
    "from exlib.features.text.identity import IdentityGroups\n",
    "from exlib.features.text.random import RandomGroups\n",
    "from exlib.features.text.word import WordGroups\n",
    "from exlib.features.text.phrase import PhraseGroups\n",
    "from exlib.features.text.sentence import SentenceGroups\n",
    "from exlib.features.text.clustering import ClusteringGroups\n",
    "from exlib.features.text.archipelago import WrappedModel, ArchipelagoGroups\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets and pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EmotionDataset(\"train\")\n",
    "model = EmotionClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10853 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: My favourite food is anything I didn't have to cook myself.\n",
      "Emotion: 18\n",
      "\n",
      "Text: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
      "Emotion: 27\n",
      "\n",
      "Text: WHY THE FUCK IS BAYLESS ISOING\n",
      "Emotion: 14\n",
      "\n",
      "Text: To make her feel threatened\n",
      "Emotion: 18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in tqdm(dataloader): \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    utterances = [dataset.tokenizer.decode(input_id, skip_special_tokens=True) for input_id in input_ids]\n",
    "    for utterance, label in zip(utterances, output.logits):\n",
    "        print(\"Text: {}\\nEmotion: {}\\n\".format(utterance, label.argmax()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "- Identity\n",
    "- Random\n",
    "- Words\n",
    "- Phrases\n",
    "- Sentences\n",
    "- Clustering\n",
    "- Archipelago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_emotion_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in scores:\n",
    "    metric = torch.tensor(scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
