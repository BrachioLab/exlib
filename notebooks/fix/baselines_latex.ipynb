{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd751879-68ec-4dc1-946c-3661b7340425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2be81d-a0dd-4036-9538-a34e63a0de7a",
   "metadata": {},
   "source": [
    "## bootstrapping\n",
    "\n",
    "for example settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36bf8f9-9917-4635-8d19-7343f626cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../fix\")\n",
    "from bootstrap import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7494a2d0-8f21-43bf-8db8-e3b1d54b0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, here for convenience:\n",
    "\n",
    "def bootstrap(scores):\n",
    "    scores_samples = []\n",
    "    means = []\n",
    "\n",
    "    for _ in range(5):\n",
    "        scores_new = torch.zeros(scores.shape)\n",
    "        for i in range(len(scores_new)):\n",
    "            # print(i)\n",
    "            index = torch.randperm(len(scores_new))[0]\n",
    "            scores_new[i] = scores[index]\n",
    "\n",
    "        means.append(torch.mean(scores_new))\n",
    "        scores_samples.append(scores_new)\n",
    "    return torch.std(torch.stack(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd85affd-875a-4c74-af4b-1007b2fb12b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& patch & 0.5618 $\\pm$ 0.0005\\\\\n",
      "& quickshift & 0.5505 $\\pm$ 0.0005\\\\\n",
      "& watershed & 0.5629 $\\pm$ 0.0004\\\\\n",
      "& oracle & 0.5930 $\\pm$ 0.0007\\\\\n",
      "& one & 0.5485 $\\pm$ 0.0008\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'mass_maps'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac90d97-5313-40e4-b8dc-dd5e7fddff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& chunk 5 & 0.0337 $\\pm$ 0.0025\\\\\n",
      "& chunk 10 & 0.0555 $\\pm$ 0.0032\\\\\n",
      "& chunk 15 & 0.0554 $\\pm$ 0.0008\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'supernova'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9247bfef-d792-42dc-8c84-ca0ec7104de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& identity & 0.4596 $\\pm$ 0.0076\\\\\n",
      "& random & 0.1081 $\\pm$ 0.0004\\\\\n",
      "& patch & 0.0322 $\\pm$ 0.0002\\\\\n",
      "& quickshift & 0.2961 $\\pm$ 0.0048\\\\\n",
      "& watershed & 0.2762 $\\pm$ 0.0048\\\\\n",
      "& sam & 0.3703 $\\pm$ 0.0048\\\\\n",
      "& neural_quickshift & 0.2868 $\\pm$ 0.0064\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'cholec'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf9c83c-df44-4518-961a-b59c403904a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& identity & 0.2191 $\\pm$ 0.0019\\\\\n",
      "& random & 0.0427 $\\pm$ 0.0002\\\\\n",
      "& patch & 0.0989 $\\pm$ 0.0010\\\\\n",
      "& quickshift & 0.3267 $\\pm$ 0.0051\\\\\n",
      "& watershed & 0.1439 $\\pm$ 0.0030\\\\\n",
      "& sam & 0.3042 $\\pm$ 0.0067\\\\\n",
      "& neural_quickshift & 0.2654 $\\pm$ 0.0041\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'chestx'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5aa1f76-bdc5-429e-af8a-28bf7b591c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& word & 0.6854 $\\pm$ 0.0016\\\\\n",
      "& phrase & 0.6350 $\\pm$ 0.0005\\\\\n",
      "& sentence & 0.6109 $\\pm$ 0.0013\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'multilingual_politeness'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eebacab-37f1-4b10-8fcb-bdf783b14074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating latex rows...\n",
      "\n",
      "& word & 0.2701 $\\pm$ 0.0005\\\\\n",
      "& phrase & 0.0425 $\\pm$ 0.0004\\\\\n",
      "& sentence & 0.0301 $\\pm$ 0.0005\\\\\n"
     ]
    }
   ],
   "source": [
    "setting = 'emotion'\n",
    "all_baselines_scores = torch.load(f'../../fix/results/{setting}/all_baselines_scores.pt')\n",
    "\n",
    "print(\"generating latex rows...\\n\")\n",
    "for name in all_baselines_scores:\n",
    "    metric = all_baselines_scores[name]\n",
    "    mean_metric = metric.mean()\n",
    "    metric_std = bootstrap(metric)\n",
    "    print(f'& {name} & {mean_metric:.4f} $\\pm$ {metric_std:.4f}' + chr(92)+ chr(92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10b4c1-6d4f-4288-9e09-8ca0f4f36b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
