{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install exlib\n",
    "# !pip install exlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80/3362772125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mexlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilingual_politeness\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolitenessDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPolitenessClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_politeness_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoliteness_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_lexica\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'exlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import sentence_transformers\n",
    "\n",
    "# import exlib\n",
    "# from exlib.datasets.multilingual_politeness import PolitenessDataset, PolitenessClassifier, Metric, get_politeness_scores\n",
    "# from exlib.utils.politeness_helper import load_lexica\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets and pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exlib\n",
    "from exlib.datasets.multilingual_politeness import PolitenessDataset, PolitenessClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample inference on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at BrachioLab/xlm-roberta-politeness and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/1140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: That is why he is a ‘pretender’. He has never claimed to be a King - or a Kaiser, for that matter. He is in the same class as the Comte de Paris, who is not the King of France, but would be if the Bourbons were placed on a restored French throne.\n",
      "Politeness: -0.07154521346092224\n",
      "\n",
      "Text: Let's knock any 'EngVar' shenanigans on the head right away, shall we? The Manual of Style, as I understand it, makes it clear that the subject's national ties and own language set the course.\n",
      "Politeness: -0.12842649221420288\n",
      "\n",
      "Text: Thank you for your contributions. There are some conventions that apply to articles, and medical articles in particular. Secondary sources were available for the material, and should be cited to validate the medical information from the studies.\n",
      "Politeness: 0.11653748154640198\n",
      "\n",
      "Text: The conversion of tacit to explicit knowledge is seen in for example the bread making machine's case. In response to your question, culture is a broad term. I would like to narrow it down to organization culture.\n",
      "Politeness: -0.01151236891746521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = PolitenessDataset(\"train\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "model = PolitenessClassifier()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(dataloader): \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    utterances = [dataset.tokenizer.decode(input_id, skip_special_tokens=True) for input_id in input_ids]\n",
    "    for utterance, label in zip(utterances, output):\n",
    "        print(\"Text: {}\\nPoliteness: {}\\n\".format(utterance, label.item()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test data + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PolitenessDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80/1328610160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolitenessDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolitenessClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PolitenessDataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = PolitenessDataset(\"test\")\n",
    "model = PolitenessClassifier()\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Alignment Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exlib.datasets.multilingual_politeness import Metric\n",
    "\n",
    "metric = Metric()\n",
    "# we define this is the get_politeness_scores function below, so this is technically redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exlib.datasets.multilingual_politeness import get_politeness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_baselines_scores = get_politeness_scores(baselines = ['word', 'phrase', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_baselines_scores:\n",
    "    metric = torch.tensor(all_baselines_scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic (Clustering)\n",
    "\n",
    "create topics from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, save all the utterances\n",
    "\n",
    "dataset = PolitenessDataset(\"test\")\n",
    "utterances = [' '.join(dataset[i]['word_list']) for i in range(len(dataset))]\n",
    "torch.save(utterances, '../../fix/utterances/multilingual_politeness_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.16.3-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.1 in /home/runai-home/.local/lib/python3.10/site-packages (from bertopic) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.2.2)\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Downloading hdbscan-0.8.38.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.5.3)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /home/runai-home/.local/lib/python3.10/site-packages (from bertopic) (3.0.1)\n",
      "Collecting plotly>=4.7.0\n",
      "  Downloading plotly-5.23.0-py3-none-any.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (23.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/runai-home/.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/runai-home/.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.44.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1+cu118)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.3.0)\n",
      "Requirement already satisfied: numba>=0.49 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.12.2)\n",
      "Requirement already satisfied: requests in /home/runai-home/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (67.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: lit in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (15.0.7)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.25.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/runai-home/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/runai-home/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (2023.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Installing collected packages: tenacity, plotly, hdbscan, bertopic\n",
      "Successfully installed bertopic-0.16.3 hdbscan-0.8.38.post1 plotly-5.23.0 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "# then, install bertopic + use them on the utterances\n",
    "\n",
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_baselines_scores = get_politeness_scoresget_politeness_scores(baselines = ['clustering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_baselines_scores:\n",
    "    metric = torch.tensor(all_baselines_scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
