{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to install exlib\n",
    "# !pip install exlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import sentence_transformers\n",
    "\n",
    "import sys\n",
    "sys.path.append('/shared_data0/chaenyk/exlib/src')\n",
    "import exlib\n",
    "from exlib.datasets.multilingual_politeness import PolitenessDataset, PolitenessClassifier, PolitenessFixScore, get_politeness_scores\n",
    "from exlib.utils.politeness_helper import load_lexica\n",
    "\n",
    "from exlib.features.text import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets and pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample inference on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2debe0e6c0c54844b9ea52157ef566b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100% 3.13M/3.13M [00:00<00:00, 5.59MB/s]\n",
      "Downloading data: 100% 391k/391k [00:00<00:00, 3.60MB/s]\n",
      "Downloading data: 100% 394k/394k [00:00<00:00, 2.43MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2619605097e4a89b040de01f4c09ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd607e1492440b0b89e80444d150faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf9e907cf144a77b10bd76e9a4d2634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5575e0bd18f4cc8b57b6261204b86e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ecc8e3f6484dab9eeea6b08c69e8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e1a153290c4236bcf653b0b629e3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9c5dd93b924b9ea6a3ed81a037db12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9665816934f9475a89a99d6859e3c4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a6fe41072849ae850011d74183c452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0338c9eba24a808283d59087a3659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at BrachioLab/xlm-roberta-politeness and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0% 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The intro mentions the ISO 8601 international standard adopted in most western countries. What does this even mean? Who are we suggesting has done the adoption?\n",
      "Politeness: 0.21642036736011505\n",
      "\n",
      "Text: I'm a user on PrettyCure.org, and somebody on the site said they are making a fourth season of PreCure. It's a rumuor, but is it true? That person said it's more like Tokyo Mew Mew, a group of girls.\n",
      "Politeness: 0.2149486541748047\n",
      "\n",
      "Text: Hello fellow Wikipedians, I have just added archive links to on Essen. Please take a moment to review my edit. If necessary, add after the link to keep me from modifying it.\n",
      "Politeness: 0.12163664400577545\n",
      "\n",
      "Text: I saw the template citing this issue and since there was no section here discussing it I've decided to start one. I'm a Canadian and most of our television programs are also aired in the US so my knowledge of what's on TV outside of North America is limited. So I'm not sure of how much help I can be, but I do have some ideas on how to improve this section and I'm open to feedback.\n",
      "Politeness: 0.09295760840177536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "dataset = PolitenessDataset(\"test\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "model = PolitenessClassifier()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(dataloader): \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    utterances = [dataset.tokenizer.decode(input_id, skip_special_tokens=True) for input_id in input_ids]\n",
    "    for utterance, label in zip(utterances, output):\n",
    "        print(\"Text: {}\\nPoliteness: {}\\n\".format(utterance, label.item()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at BrachioLab/xlm-roberta-politeness and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a79fcae77f14daf941799daca5679ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5126cd8a16734d82bd3485c46059522b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c970c34535594fa39e3bbe6c8e0dc30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b518829309264924b692bf6c60e26001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c83b8758374a1d93b3fea4ccd590eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acc888c9eef4832a7e6be661d38e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3da448cff2749019f2e6579e902d62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0db4c6a0f2c475891558c3b6d43e309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a89aa5010d4e2d9910c161d8ceefdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e14cc9221ec4867bb8fbee742f2cea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442d2a927a924648bd4672a052b56f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4848f2f9ea9640bcba47db8ed1f31bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9bfc7974a345618c45f6419acf6071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c90d7eb995745f18af7a372a80b1df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb18eafd64e45f1aae0aaba1b6a60fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c249bd7bd344f7dac1d0bbaf3f49279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "english_politelex.csv:   0%|          | 0.00/163k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c347eb69c7f46f58b54b8bf45759b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spanish_politelex.csv:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55254ce7691448c2a584d0e957b4ccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chinese_politelex.csv:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86295e54eae74c2c8cf707d7f1eb3954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "japanese_politelex.csv:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids for english created.\n",
      "Centroids for spanish created.\n",
      "Centroids for chinese created.\n",
      "Centroids for japanese created.\n",
      "---- word Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 143/143 [01:51<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- phrase Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 143/143 [02:33<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- sentence Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 143/143 [02:22<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "all_baselines_scores = get_politeness_scores(baselines = ['word', 'phrase', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE word mean score: 0.6839182666768004\n",
      "BASELINE phrase mean score: 0.635053510664725\n",
      "BASELINE sentence mean score: 0.610872678710197\n"
     ]
    }
   ],
   "source": [
    "for name in all_baselines_scores:\n",
    "    metric = torch.tensor(all_baselines_scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic (Clustering)\n",
    "\n",
    "create topics from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, save all the utterances\n",
    "\n",
    "dataset = PolitenessDataset(\"test\")\n",
    "utterances = [' '.join(dataset[i]['word_list']) for i in range(len(dataset))]\n",
    "torch.save(utterances, '../../fix/utterances/multilingual_politeness_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in /opt/conda/envs/rapids/lib/python3.10/site-packages (0.16.3)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (0.5.3)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (0.8.38.post1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.2.2)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (5.24.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (1.23.5)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from bertopic) (2.7.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (23.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.34.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.17.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.0.1+cu118)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.8)\n",
      "Requirement already satisfied: numba>=0.49 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (67.6.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.25.0)\n",
      "Requirement already satisfied: lit in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (15.0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.3.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.4.1->bertopic) (0.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# then, install bertopic + use them on the utterances\n",
    "\n",
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at BrachioLab/xlm-roberta-politeness and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids for english created.\n",
      "Centroids for spanish created.\n",
      "Centroids for chinese created.\n",
      "Centroids for japanese created.\n",
      "---- clustering Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:19<00:00,  7.35it/s]\n"
     ]
    }
   ],
   "source": [
    "all_baselines_scores = get_politeness_scores(baselines = ['clustering'], \\\n",
    "                                             utterances_path='../../fix/utterances/multilingual_politeness_test.pt')\n",
    "\n",
    "# make sure utterances_path is set to where utteraces is saved in your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE clustering mean score: 0.6691428461948472\n"
     ]
    }
   ],
   "source": [
    "for name in all_baselines_scores:\n",
    "    metric = torch.tensor(all_baselines_scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at BrachioLab/xlm-roberta-politeness and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids for english created.\n",
      "Centroids for spanish created.\n",
      "Centroids for chinese created.\n",
      "Centroids for japanese created.\n",
      "---- identity Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [01:52<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- random Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [02:10<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- word Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [01:24<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- phrase Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [02:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- sentence Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [01:54<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- archipelago Level Groups ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 125/143 [45:50<06:12, 20.67s/it]"
     ]
    }
   ],
   "source": [
    "all_baselines_scores = get_politeness_scores(utterances_path='../../fix/utterances/multilingual_politeness_test.pt')\n",
    "\n",
    "for name in all_baselines_scores:\n",
    "    metric = torch.tensor(all_baselines_scores[name])\n",
    "    mean_metric = metric.nanmean()\n",
    "    print(f'BASELINE {name} mean score: {mean_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
