{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import TextClassificationPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "from transformers import Pipeline\n",
    "from torch import Tensor \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import sentence_transformers\n",
    "from projection_helper import project_points_onto_axes\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_REPO = \"go_emotions\"\n",
    "MODEL_REPO = \"shreyahavaldar/roberta-base-go_emotions\"\n",
    "\n",
    "def load_data():\n",
    "    hf_dataset = load_dataset(DATASET_REPO, \"raw\")\n",
    "    #convert to torch dataset\n",
    "    hf_dataset.set_format(type='torch')\n",
    "    return hf_dataset\n",
    "\n",
    "def load_model():\n",
    "    model = AutoModel.from_pretrained(MODEL_REPO)\n",
    "    #convert to pytorch model\n",
    "    torch_model = nn.Sequential(model, nn.Linear(model.config.hidden_size, 28))\n",
    "    model.to(device)\n",
    "    return torch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Alignment Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(nn.Module): \n",
    "    def __init__(self, model_name:str=\"distiluse-base-multilingual-cased\"): \n",
    "        super(Metric, self).__init__()\n",
    "        self.model = sentence_transformers.SentenceTransformer(model_name)\n",
    "        points = self.define_circumplex()\n",
    "        self.x1 = points[0]\n",
    "        self.x2 = points[1]\n",
    "        self.y1 = points[3]\n",
    "        self.y2 = points[2]\n",
    "\n",
    "    def define_circumplex(self):\n",
    "        emotions = pd.read_csv(\"russell_emotions.csv\")\n",
    "        axis_labels = [\"NV\", \"PV\", \"HA\", \"LA\"]\n",
    "        axis_points = []\n",
    "        for label in axis_labels:\n",
    "            emotion_words = emotions[emotions[\"label\"] == label][\"emotion\"].values\n",
    "            emotion_embeddings = self.model.encode(emotion_words)\n",
    "            axis_points.append(np.mean(emotion_embeddings, axis=0))\n",
    "        return axis_points\n",
    "    \n",
    "    def distance_from_circumplex(self, embeddings):\n",
    "        projection = project_points_onto_axes(embeddings, self.x1, self.x2, self.y1, self.y2)\n",
    "        x_projections = projection[0]\n",
    "        y_projections = projection[1]\n",
    "        distances = []\n",
    "        for x, y in zip(x_projections, y_projections):\n",
    "            distances.append(np.abs(np.sqrt(x**2 + y**2)-1))\n",
    "        return np.mean(distances)\n",
    "\n",
    "    # input: list of words\n",
    "    def calculate_group_alignment(self, groups:list, language:str=\"english\"):\n",
    "        distances = []\n",
    "        for group in groups:\n",
    "            embeddings = self.model.encode(group)\n",
    "            distances.append(self.distance_from_circumplex(embeddings))\n",
    "        return distances\n",
    "        \n",
    "    def forward(self, zp, x=None, y=None, z=None, reduce=True, **kwargs): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Group Alignment Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: ['however', 'therefore', 'unless'], Alignment: 0.8077621152905459\n",
      "Group: ['sad', 'happy', 'thrilled'], Alignment: 0.32860005172434187\n",
      "Group: ['computer', 'neural network', 'compiler'], Alignment: 0.6724962101561861\n",
      "Group: ['tired', 'sleepy', 'calm'], Alignment: 0.34622350256426504\n"
     ]
    }
   ],
   "source": [
    "metric = Metric()\n",
    "sample_groups = [[\"however\", \"therefore\", \"unless\"], \n",
    "                [\"sad\", \"happy\", \"thrilled\"], \n",
    "                [\"computer\", \"neural network\", \"compiler\"], \n",
    "                [\"tired\", \"sleepy\", \"calm\"]]\n",
    "alignments = metric.calculate_group_alignment(sample_groups)\n",
    "for group, alignment in zip(sample_groups, alignments):\n",
    "    print(f\"Group: {group}, Alignment: {alignment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtop",
   "language": "python",
   "name": "vtop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
